{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNrhipKghS5VLJ/Inhj8QBb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jpnoxon/jpnoxon_64061_MachineLearning/blob/main/Assignment1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEqBujLXv_kY"
      },
      "source": [
        "from tensorflow.keras.datasets import imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(\n",
        "    num_words=10000)\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81xPpvSlwGDa",
        "outputId": "f55fed81-fd71-4e40-d6bc-12f803e3c490"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 14,\n",
              " 22,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 973,\n",
              " 1622,\n",
              " 1385,\n",
              " 65,\n",
              " 458,\n",
              " 4468,\n",
              " 66,\n",
              " 3941,\n",
              " 4,\n",
              " 173,\n",
              " 36,\n",
              " 256,\n",
              " 5,\n",
              " 25,\n",
              " 100,\n",
              " 43,\n",
              " 838,\n",
              " 112,\n",
              " 50,\n",
              " 670,\n",
              " 2,\n",
              " 9,\n",
              " 35,\n",
              " 480,\n",
              " 284,\n",
              " 5,\n",
              " 150,\n",
              " 4,\n",
              " 172,\n",
              " 112,\n",
              " 167,\n",
              " 2,\n",
              " 336,\n",
              " 385,\n",
              " 39,\n",
              " 4,\n",
              " 172,\n",
              " 4536,\n",
              " 1111,\n",
              " 17,\n",
              " 546,\n",
              " 38,\n",
              " 13,\n",
              " 447,\n",
              " 4,\n",
              " 192,\n",
              " 50,\n",
              " 16,\n",
              " 6,\n",
              " 147,\n",
              " 2025,\n",
              " 19,\n",
              " 14,\n",
              " 22,\n",
              " 4,\n",
              " 1920,\n",
              " 4613,\n",
              " 469,\n",
              " 4,\n",
              " 22,\n",
              " 71,\n",
              " 87,\n",
              " 12,\n",
              " 16,\n",
              " 43,\n",
              " 530,\n",
              " 38,\n",
              " 76,\n",
              " 15,\n",
              " 13,\n",
              " 1247,\n",
              " 4,\n",
              " 22,\n",
              " 17,\n",
              " 515,\n",
              " 17,\n",
              " 12,\n",
              " 16,\n",
              " 626,\n",
              " 18,\n",
              " 2,\n",
              " 5,\n",
              " 62,\n",
              " 386,\n",
              " 12,\n",
              " 8,\n",
              " 316,\n",
              " 8,\n",
              " 106,\n",
              " 5,\n",
              " 4,\n",
              " 2223,\n",
              " 5244,\n",
              " 16,\n",
              " 480,\n",
              " 66,\n",
              " 3785,\n",
              " 33,\n",
              " 4,\n",
              " 130,\n",
              " 12,\n",
              " 16,\n",
              " 38,\n",
              " 619,\n",
              " 5,\n",
              " 25,\n",
              " 124,\n",
              " 51,\n",
              " 36,\n",
              " 135,\n",
              " 48,\n",
              " 25,\n",
              " 1415,\n",
              " 33,\n",
              " 6,\n",
              " 22,\n",
              " 12,\n",
              " 215,\n",
              " 28,\n",
              " 77,\n",
              " 52,\n",
              " 5,\n",
              " 14,\n",
              " 407,\n",
              " 16,\n",
              " 82,\n",
              " 2,\n",
              " 8,\n",
              " 4,\n",
              " 107,\n",
              " 117,\n",
              " 5952,\n",
              " 15,\n",
              " 256,\n",
              " 4,\n",
              " 2,\n",
              " 7,\n",
              " 3766,\n",
              " 5,\n",
              " 723,\n",
              " 36,\n",
              " 71,\n",
              " 43,\n",
              " 530,\n",
              " 476,\n",
              " 26,\n",
              " 400,\n",
              " 317,\n",
              " 46,\n",
              " 7,\n",
              " 4,\n",
              " 2,\n",
              " 1029,\n",
              " 13,\n",
              " 104,\n",
              " 88,\n",
              " 4,\n",
              " 381,\n",
              " 15,\n",
              " 297,\n",
              " 98,\n",
              " 32,\n",
              " 2071,\n",
              " 56,\n",
              " 26,\n",
              " 141,\n",
              " 6,\n",
              " 194,\n",
              " 7486,\n",
              " 18,\n",
              " 4,\n",
              " 226,\n",
              " 22,\n",
              " 21,\n",
              " 134,\n",
              " 476,\n",
              " 26,\n",
              " 480,\n",
              " 5,\n",
              " 144,\n",
              " 30,\n",
              " 5535,\n",
              " 18,\n",
              " 51,\n",
              " 36,\n",
              " 28,\n",
              " 224,\n",
              " 92,\n",
              " 25,\n",
              " 104,\n",
              " 4,\n",
              " 226,\n",
              " 65,\n",
              " 16,\n",
              " 38,\n",
              " 1334,\n",
              " 88,\n",
              " 12,\n",
              " 16,\n",
              " 283,\n",
              " 5,\n",
              " 16,\n",
              " 4472,\n",
              " 113,\n",
              " 103,\n",
              " 32,\n",
              " 15,\n",
              " 16,\n",
              " 5345,\n",
              " 19,\n",
              " 178,\n",
              " 32]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8Gra1vrwJRu",
        "outputId": "cd73fa5e-6073-4c9c-b66b-3b5c0131a501"
      },
      "source": [
        "train_labels[0]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DtoXRIn3wLb4",
        "outputId": "d3bf3b87-b6a4-499d-a2b9-31fd9df02a84"
      },
      "source": [
        "max([max(sequence) for sequence in train_data])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9999"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDeWdu1ewNyD"
      },
      "source": [
        "word_index = imdb.get_word_index()\n",
        "reverse_word_index = dict(\n",
        "    [(value, key) for (key, value) in word_index.items()])\n",
        "decoded_review = \" \".join(\n",
        "    [reverse_word_index.get(i - 3, \"?\") for i in train_data[0]])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA7KUYFfwP42"
      },
      "source": [
        "import numpy as np\n",
        "def vectorize_sequences(sequences, dimension=10000):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        for j in sequence:\n",
        "            results[i, j] = 1.\n",
        "    return results\n",
        "x_train = vectorize_sequences(train_data)\n",
        "x_test = vectorize_sequences(test_data)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzU9GgoSwSEs",
        "outputId": "661e4adb-80fb-461c-9810-2c0316a54b03"
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 1., ..., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfmLvPrxwUNU"
      },
      "source": [
        "y_train = np.asarray(train_labels).astype(\"float32\")\n",
        "y_test = np.asarray(test_labels).astype(\"float32\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9vFbaML_wW1y"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWO--MG9wZvF"
      },
      "source": [
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kvYxMuqwhJ4"
      },
      "source": [
        "x_val = x_train[:10000]\n",
        "partial_x_train = x_train[10000:]\n",
        "y_val = y_train[:10000]\n",
        "partial_y_train = y_train[10000:]\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "sLO1n0m3wl_z",
        "outputId": "f9f585fe-cda2-4e65-beb0-15b709941045"
      },
      "source": [
        "history = model.fit(partial_x_train,\n",
        "                    partial_y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=512,\n",
        "                    validation_data=(x_val, y_val))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "30/30 [==============================] - 2s 42ms/step - loss: 0.5368 - accuracy: 0.7761 - val_loss: 0.3870 - val_accuracy: 0.8537\n",
            "Epoch 2/20\n",
            "30/30 [==============================] - 1s 31ms/step - loss: 0.2872 - accuracy: 0.9031 - val_loss: 0.2942 - val_accuracy: 0.8864\n",
            "Epoch 3/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1981 - accuracy: 0.9337 - val_loss: 0.2797 - val_accuracy: 0.8881\n",
            "Epoch 4/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1487 - accuracy: 0.9517 - val_loss: 0.2817 - val_accuracy: 0.8861\n",
            "Epoch 5/20\n",
            "30/30 [==============================] - 1s 30ms/step - loss: 0.1148 - accuracy: 0.9679 - val_loss: 0.2976 - val_accuracy: 0.8846\n",
            "Epoch 6/20\n",
            "15/30 [==============>...............] - ETA: 0s - loss: 0.0890 - accuracy: 0.9780"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-90a50ee7d258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_data=(x_val, y_val))\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3040\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1964\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "U6qSvkmkwojp",
        "outputId": "a52a7e7d-103c-459a-f88b-9cb00e4fdaeb"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = history.history\n",
        "loss_values = history_dict[\"loss\"]\n",
        "val_loss_values = history_dict[\"val_loss\"]\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "plt.plot(epochs, loss_values, \"bo\", label=\"Training loss\")\n",
        "plt.plot(epochs, val_loss_values, \"b\", label=\"Validation loss\")\n",
        "plt.title(\"Training and validation loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9gH38mxw-GW"
      },
      "source": [
        "We can see that the easiest way to improve this model is by reducing the number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkf-c5YtxLoY",
        "outputId": "05e2f70b-adcd-4e62-d62e-71b72e2c9920"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.4446 - accuracy: 0.8174 - val_loss: 0.2766 - val_accuracy: 0.9160\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.2534 - accuracy: 0.9107 - val_loss: 0.1989 - val_accuracy: 0.9350\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.1978 - accuracy: 0.9292 - val_loss: 0.1585 - val_accuracy: 0.9478\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.1665 - accuracy: 0.9402 - val_loss: 0.1284 - val_accuracy: 0.9627\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.2941 - accuracy: 0.8840\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65Jy8MoPyYiD"
      },
      "source": [
        "Even though model accuracy on training data is lower, validation accuracy has increased.  This is better since it means our model is not over fitted.  It will better predict general results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YubCvog1ysx4"
      },
      "source": [
        "Next, let's test if batch size impacts validation & test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnbJQMsPyx9z",
        "outputId": "4f5136a8-a79a-43bb-9841-0c20957b8ea1"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=1024, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "25/25 [==============================] - 2s 70ms/step - loss: 0.5233 - accuracy: 0.7931 - val_loss: 0.3812 - val_accuracy: 0.8869\n",
            "Epoch 2/4\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.3382 - accuracy: 0.8931 - val_loss: 0.2774 - val_accuracy: 0.9156\n",
            "Epoch 3/4\n",
            "25/25 [==============================] - 1s 56ms/step - loss: 0.2591 - accuracy: 0.9166 - val_loss: 0.2164 - val_accuracy: 0.9356\n",
            "Epoch 4/4\n",
            "25/25 [==============================] - 1s 55ms/step - loss: 0.2127 - accuracy: 0.9279 - val_loss: 0.1854 - val_accuracy: 0.9418\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.2936 - accuracy: 0.8835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fn8F6xmGzaN7"
      },
      "source": [
        "Doubling batch size has a neglible effect"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBiQTCYxzeSX",
        "outputId": "ad6ec335-4526-4960-9012-2cabe4928e47"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=2036, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "13/13 [==============================] - 2s 113ms/step - loss: 0.6095 - accuracy: 0.7228 - val_loss: 0.4991 - val_accuracy: 0.8465\n",
            "Epoch 2/4\n",
            "13/13 [==============================] - 1s 93ms/step - loss: 0.4521 - accuracy: 0.8650 - val_loss: 0.3835 - val_accuracy: 0.9049\n",
            "Epoch 3/4\n",
            "13/13 [==============================] - 1s 92ms/step - loss: 0.3567 - accuracy: 0.8997 - val_loss: 0.3216 - val_accuracy: 0.9127\n",
            "Epoch 4/4\n",
            "13/13 [==============================] - 1s 89ms/step - loss: 0.3012 - accuracy: 0.9123 - val_loss: 0.2651 - val_accuracy: 0.9285\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3394 - accuracy: 0.8765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6-cqpDH2DEk"
      },
      "source": [
        "After doubling the batch size and then increasing the batch size by almost 4x, slightly increasing the batch size does not drastically increase model performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKfZfxbs2gUe",
        "outputId": "fa945e98-f614-4dda-ad48-2d204fe0b167"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(16, activation= \"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 2s 36ms/step - loss: 0.4759 - accuracy: 0.7969 - val_loss: 0.2885 - val_accuracy: 0.8966\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.2531 - accuracy: 0.9067 - val_loss: 0.2008 - val_accuracy: 0.9287\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 2s 31ms/step - loss: 0.1970 - accuracy: 0.9265 - val_loss: 0.1468 - val_accuracy: 0.9516\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.1592 - accuracy: 0.9435 - val_loss: 0.1391 - val_accuracy: 0.9496\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.3369 - accuracy: 0.8729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yp8wDA3H4MKm"
      },
      "source": [
        "Adding an exra layer increased validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLawhH5C4ZY3",
        "outputId": "55b98dd0-0a1e-424f-be19-e6d9bc97f23d"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 2s 32ms/step - loss: 0.4661 - accuracy: 0.8154 - val_loss: 0.3033 - val_accuracy: 0.9013\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.2671 - accuracy: 0.9089 - val_loss: 0.2198 - val_accuracy: 0.9309\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.2104 - accuracy: 0.9298 - val_loss: 0.1803 - val_accuracy: 0.9448\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.1783 - accuracy: 0.9421 - val_loss: 0.1551 - val_accuracy: 0.9533\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.2850 - accuracy: 0.8866\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gY_jVFH5uM1"
      },
      "source": [
        "removing a hidden layer did not have a significant impact"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxG-v8lP5x0B",
        "outputId": "53a6081e-441b-4245-8cc5-ef84f9cb37b5"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(32, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 2s 39ms/step - loss: 0.4467 - accuracy: 0.8224 - val_loss: 0.2709 - val_accuracy: 0.9110\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.2423 - accuracy: 0.9170 - val_loss: 0.1927 - val_accuracy: 0.9377\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.1877 - accuracy: 0.9358 - val_loss: 0.1542 - val_accuracy: 0.9534\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 2s 33ms/step - loss: 0.1543 - accuracy: 0.9484 - val_loss: 0.1294 - val_accuracy: 0.9633\n",
            "782/782 [==============================] - 2s 2ms/step - loss: 0.2982 - accuracy: 0.8807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmDwSEGa5_ym"
      },
      "source": [
        "adding nodes to the model increased validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vq6q0TY16Ejf",
        "outputId": "ce562332-65ee-488e-cb01-924507eb3214"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.4995 - accuracy: 0.7995 - val_loss: 0.3422 - val_accuracy: 0.8901\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 2s 35ms/step - loss: 0.3022 - accuracy: 0.9008 - val_loss: 0.2538 - val_accuracy: 0.9218\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 2s 30ms/step - loss: 0.2399 - accuracy: 0.9219 - val_loss: 0.2119 - val_accuracy: 0.9351\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.2044 - accuracy: 0.9328 - val_loss: 0.1833 - val_accuracy: 0.9439\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.2901 - accuracy: 0.8853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOHU9p9j6L_c"
      },
      "source": [
        "removing nodes slightly decrease validation accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is3Svqsa5T4W",
        "outputId": "3a056768-e1ca-420b-f062-8f6e5ea09e95"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.5898 - accuracy: 0.7764 - val_loss: 0.4062 - val_accuracy: 0.8917\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.3108 - accuracy: 0.9019 - val_loss: 0.2221 - val_accuracy: 0.9277\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 1s 29ms/step - loss: 0.2070 - accuracy: 0.9288 - val_loss: 0.1641 - val_accuracy: 0.9476\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 30ms/step - loss: 0.1630 - accuracy: 0.9442 - val_loss: 0.1314 - val_accuracy: 0.9606\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.2945 - accuracy: 0.8846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fo0tXcvI6sg3"
      },
      "source": [
        "adding additional layers and alternating node size increased validation accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myQ50ors7VA5",
        "outputId": "fec51ccb-a894-4b50-afa5-17d825cababd"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(16, activation=\"relu\"),\n",
        "    layers.Dense(8, activation=\"relu\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"mse\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 3s 47ms/step - loss: 0.2056 - accuracy: 0.6697 - val_loss: 0.1451 - val_accuracy: 0.8638\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.1009 - accuracy: 0.8969 - val_loss: 0.0619 - val_accuracy: 0.9321\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.0569 - accuracy: 0.9322 - val_loss: 0.0424 - val_accuracy: 0.9554\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 27ms/step - loss: 0.0421 - accuracy: 0.9518 - val_loss: 0.0309 - val_accuracy: 0.9693\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.8814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTCPVVBbDA39"
      },
      "source": [
        "using mse instead of binary cross entropy slight increased validation accuracy "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J968mmYLDNPA",
        "outputId": "8b7345e3-032d-448d-c48b-98d27ae9d871"
      },
      "source": [
        "model = keras.Sequential([\n",
        "    layers.Dense(8, activation=\"tanh\"),\n",
        "    layers.Dense(16, activation=\"tanh\"),\n",
        "    layers.Dense(8, activation=\"tanh\"),\n",
        "    layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"mse\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.fit(x_train, y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))\n",
        "results = model.evaluate(x_test, y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4\n",
            "49/49 [==============================] - 2s 32ms/step - loss: 0.1620 - accuracy: 0.8083 - val_loss: 0.0898 - val_accuracy: 0.9002\n",
            "Epoch 2/4\n",
            "49/49 [==============================] - 1s 26ms/step - loss: 0.0749 - accuracy: 0.9113 - val_loss: 0.0526 - val_accuracy: 0.9432\n",
            "Epoch 3/4\n",
            "49/49 [==============================] - 1s 28ms/step - loss: 0.0507 - accuracy: 0.9411 - val_loss: 0.0392 - val_accuracy: 0.9604\n",
            "Epoch 4/4\n",
            "49/49 [==============================] - 1s 27ms/step - loss: 0.0380 - accuracy: 0.9592 - val_loss: 0.0271 - val_accuracy: 0.9745\n",
            "782/782 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.8798\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSw7yl6IDhYS"
      },
      "source": [
        "I ran the model results several times using tanh and MSE together and it increase validation accuracy a decent amount"
      ]
    }
  ]
}